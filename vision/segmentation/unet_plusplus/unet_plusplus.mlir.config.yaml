---

name: unet_plusplus
gops: [60.036]
shapes:
  - [1, 3, 256, 256]

mlir_transform:
  model_transform.py
    --model_name $(name)
    --model_def $(home)/unet_plusplus_cityscapes/model.onnx
    --test_input $(root)/dataset/samples/stock_market.jpg
    --input_shapes [$(shape_param)]
    --mean=127.5,127.5,127.5
    --scale=0.0078431,0.0078431,0.0078431
    --pixel_format rgb
    --test_result $(name)_top_outputs.npz
    --mlir $(workdir)/transformed.mlir

mlir_calibration:
  run_calibration.py $(workdir)/transformed.mlir
    --dataset $(coco2017_mlir_cali_set)
    --input_num 1
    -o $(workdir)/$(name).cali_table

BM1684X:
  deploy:
    - model_deploy.py  --mlir $(workdir)/transformed.mlir
        --quantize F32
        --chip bm1684x
        --test_input $(workdir)/$(name)_in_f32.npz
        --test_reference $(name)_top_outputs.npz
        --tolerance 0.99,0.99
        --excepts   argmax_0.tmp_0_ArgMax
        --model $(workdir)/$(name)_bm1684x_f32.bmodel
    - model_deploy.py --mlir $(workdir)/transformed.mlir
        --quantize F16
        --chip bm1684x
        --test_input $(workdir)/$(name)_in_f32.npz
        --test_reference $(name)_top_outputs.npz
        --tolerance 0.95,0.85
        --excepts   argmax_0.tmp_0_ArgMax
        --model $(workdir)/$(name)_bm1684x_f16.bmodel
    - model_deploy.py --mlir $(workdir)/transformed.mlir
        --quantize BF16
        --chip bm1684x
        --test_input $(workdir)/$(name)_in_f32.npz
        --test_reference $(name)_top_outputs.npz
        --tolerance 0.95,0.85
        --excepts   argmax_0.tmp_0_ArgMax
        --model $(workdir)/$(name)_bm1684x_bf16.bmodel
    - model_deploy.py --mlir $(workdir)/transformed.mlir
        --quantize INT8
        --calibration_table $(workdir)/$(name).cali_table
        --chip bm1684x
        --test_input $(workdir)/$(name)_in_f32.npz
        --test_reference $(name)_top_outputs.npz
        --tolerance 0.99,0.86
        --excepts   argmax_0.tmp_0_ArgMax
        --quant_input
        --quant_output
        --model $(workdir)/$(name)_bm1684x_int8_sym.bmodel
    - model_deploy.py --mlir $(workdir)/transformed.mlir
        --quantize INT8
        --asymmetric
        --calibration_table $(workdir)/$(name).cali_table
        --chip bm1684x
        --test_input $(workdir)/$(name)_in_f32.npz
        --test_reference $(name)_top_outputs.npz
        --tolerance 0.99,0.86
        --excepts   argmax_0.tmp_0_ArgMax
        --quant_input
        --quant_output
        --model $(workdir)/$(name)_bm1684x_int8_asym.bmodel

BM1684:
  deploy:
    - model_deploy.py  --mlir $(workdir)/transformed.mlir
        --quantize F32
        --chip bm1684
        --test_input $(workdir)/$(name)_in_f32.npz
        --test_reference $(name)_top_outputs.npz
        --tolerance 0.99,0.99
        --model $(workdir)/$(name)_bm1684_f32.bmodel
    - model_deploy.py --mlir $(workdir)/transformed.mlir
        --quantize INT8
        --calibration_table $(workdir)/$(name).cali_table
        --chip bm1684
        --test_input $(workdir)/$(name)_in_f32.npz
        --test_reference $(name)_top_outputs.npz
        --tolerance 0.8,0.4
        --excepts   argmax_0.tmp_0_ArgMax
        --quant_input
        --quant_output
        --model $(workdir)/$(name)_bm1684_int8_sym.bmodel
